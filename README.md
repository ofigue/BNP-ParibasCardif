# BNP-ParibasCardif
Kaggle Competition: BNP Paribas Cardif
Website: https://www.kaggle.com/c/bnp-paribas-cardif-claims-management
Date: February to April 2016
	Autor: MSc. Oswaldo F. Domejean
Email: ofigue@gmail.com
Lugar: La Paz – BOLIVIA
Code: . . .


Business understanding

From the competition site description:
As a global specialist in personal insurance, BNP Paribas Cardif serves 90 million clients in 36 countries across Europe, Asia and Latin America.
In a world shaped by the emergence of new uses and lifestyles, everything is going faster and faster. When facing unexpected events, customers expect their insurer to support them as soon as possible. However, claims management may require different levels of check before a claim can be approved and a payment can be made. With the new practices and behaviors generated by the digital economy, this process needs adaptation thanks to data science to meet the new needs and expectations of customers.
In this challenge, BNP Paribas Cardif is providing an anonymized database with two categories of claims:
1.	claims for which approval could be accelerated leading to faster payments
2.	claims for which additional information is required before approval
Kagglers are challenged to predict the category of a claim based on features available early in the process, helping BNP Paribas Cardif accelerate its claims process and therefore provide a better service to its customers.

Data

The dataset is anonymized, the variable names begin with “v” and the number of feature, and also the label is named “target”, then no information at all. 

Data exploration

The dataset had a lot of NA values, around 40%, and then the analysis is reduced to correlation between variables, distributions, trying to “guess” the meaning of the variables.

Something that was very unusual was that in the case of NAs there were patterns, I mean, it was not something that randomly occurred, besides from some few feature values, most of the NAs showed up in patterns. In these conditions it is a matter of trial an error to try to identify some meaning in the data. 

Something very unusual was that there were a lost of high correlations between variable, it reached 0.95 or more of correlations between features for about half or more of them.

Feature engineering

In the case of feature engineering, it was just a matter of identifying some interactions, operations between features to get some meaningful information that could help in the predictions.

Because there were no hint about the meaning of the variables it as a trial and error process to try to identify some meaningful concepts in the data. In order to identify the most valuable features, it had been used models like Random forest or GBM to identify the important features.

Another thing that draw my attention was the fact that the graphics with some features, especially in the case of scatter plots, showed very unusual ones, some of them looked like very sophisticated painting, showing very unusual correlations.

Models and Evaluation

It had been used models like XGBoost, Random forest, GLMNET, also GBM, but XGBoost was the one with the highest scores, the other ones helped in the ensemble.

Something that initially had been done was the division of the dataset based on the existence or not of NAs, with the hope to get higher scores, but it did not happened.

The ensemble used was using a 5 fold cross-validation, calculating with every model´s fold the prediction for the test and having all five predictions just get the average of them to get the final prediction.



Conclusion

Besides from the fact that there were lots of NAs, anonymized feature names and also high levels of correlations, it was very nice to try with different models and different set of features.

Something that draw my attention was the fact that the inclusion of highly correlated features in the predictions helped, maybe just 



